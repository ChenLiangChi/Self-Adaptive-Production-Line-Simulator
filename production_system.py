import threading
import queue
import os
import time
from openai import OpenAI
import json
import math

# Initial values for caculating plastic waste
temperature = 250   # Example temperature
pressure = 100      # Example pressure

# Set API key for LLM
client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),
)

# Shared message queues
goal_queue = queue.Queue()      # High-level goals (Multi-Objective Optimization)
strategy_queue = queue.Queue()  # Strategies generated by LLM
data_queue = queue.Queue()      # Updated production line data

# Synchronization events for strict sequential execution
goal_done = threading.Event()
data_collector_done = threading.Event()
strategy_management_done = threading.Event()
strategy_enactment_done = threading.Event()

# Initialize the first cycle
strategy_enactment_done.set()

# Function to calculate plastic waste
def calculate_plastic_waste(T, P, T_opt=160, P_opt=60, a=0.001, b=0.01, W_min=5):
    """
    Calculate plastic waste based on deviations from optimal temperature and pressure.
    
    Args:
        T (float): Temperature.
        P (float): Pressure.
        T_opt (float): Optimal temperature where waste is minimal.
        P_opt (float): Optimal pressure where waste is minimal.
        a (float): Weight for temperature deviation.
        b (float): Weight for pressure deviation.
        W_min (float): Minimum waste percentage.
    
    Returns:
        float: Plastic waste percentage.
    """
    # Calculate squared deviations
    temp_deviation = a * (T - T_opt) ** 2
    press_deviation = b * (P - P_opt) ** 2

    # Combine deviations and add the minimum waste
    W = W_min + temp_deviation + press_deviation
    return round(W)  # Return integer value

# Simulate high-level goal parsing
def goal_management():
    while True:
        strategy_enactment_done.wait()  # Wait for the previous cycle to finish
        strategy_enactment_done.clear()

        # Set a new goal and proceed
        goal = "plastic_waste must be less than 8%"  # OM can extend this to multiple goals (Must be very specific)
        
        # Retrieve the latest production data from the queue
        if not data_queue.empty():
            production_data = data_queue.get()

            # Use LLM to analyze if the production data meets the goal
            prompt = (
                f"The production line data is as follows: {json.dumps(production_data)}. "
                f"The goal is '{goal}'. "
                "Analyze whether the 'plastic_waste' value in the production line data meets the goal. "
                "If the 'plastic_waste' value is less than or equal to the target in the goal, return only 'Goal Achieved'. "
                "Otherwise, return only 'Goal Not Achieved'. Do not perform any calculations or provide any suggestions."
            )

            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are a production line goal optimization assistant responsible for analyzing data and goals."},
                        {"role": "user", "content": prompt}
                    ],
                )
                analysis = response.choices[0].message.content.strip()
                print(f"1. Goal Management Layer: Analysis -> {analysis}", end="\n")

                # Check the analysis result
                if "Goal Achieved" in analysis:
                    print(f"1. Goal Management Layer: Goal achieved. Terminating the program...", end="\n")
                    os._exit(0)  # Terminate the program when the goal is achieved
                else:
                    print("1. Goal Management Layer: Goal not achieved. Continuing the process...", end="\n")
            except Exception as e:
                print(f"1. Goal Management Layer: Error occurred -> {e}", end="\n")

        print("----------", end="\n")
        print(f"1. Goal Management Layer: New goal -> {goal}", end="\n")
        goal_queue.put(goal)
        time.sleep(1)
        goal_done.set()  

def data_collector():
    global temperature, pressure
    while True:
        goal_done.wait() 
        goal_done.clear()
        
        plastic_waste = calculate_plastic_waste(temperature, pressure)

        # Construct production data
        production_data = {
            "temperature": temperature,
            "pressure": pressure,
            "plastic_waste": plastic_waste,
            "machine_status": "running",
        }
        
        print(f"2. Data Collection Layer: Received production line data -> {json.dumps(production_data)}", end = "\n")
        data_queue.put(production_data)
        time.sleep(1)
        data_collector_done.set()  

def strategy_management():
    while True:
        data_collector_done.wait()  
        data_collector_done.clear()
        
        if not goal_queue.empty() and not data_queue.empty():
            goal = goal_queue.get()
            production_data = data_queue.get()

            # Use LLM to generate strategy based on goals and data
            prompt = (
                f"The goal is '{goal}'. Production line data as follows: {json.dumps(production_data)}. "
                "Adjust the temperature and pressure to achieve the goal. "
                "Return the result as pure JSON in the format: "
                '{"temperature": <new_temperature>, "pressure": <new_pressure>, "plastic_waste": <unchanged>, "machine_status": "running"}. '
                "Do not include any explanation or additional text."
            )

            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are a production line strategy optimization assistant responsible for generating strategies based on data and goals."},
                        {"role": "user", "content": prompt}
                    ],
                )
                strategy = response.choices[0].message.content.strip()
                print(f"3. Strategy Management Layer: Generated strategy -> {strategy}", end = "\n")
                try:
                    strategy_data = json.loads(strategy)
                    strategy_queue.put(strategy_data)
                except json.JSONDecodeError:
                    print(f"3. Strategy Management Layer: Failed to parse JSON -> {strategy}")
            except Exception as e:
                print(f"3. Strategy Management Layer: Error occurred -> {e}")

            time.sleep(5)
            strategy_management_done.set() 

def strategy_enactment():
    global temperature, pressure
    while True:
        strategy_management_done.wait()  
        strategy_management_done.clear()
        
        if not strategy_queue.empty():
            strategy = strategy_queue.get()   # Extract strategy generated by LLM
            temperature = strategy["temperature"]
            pressure = strategy["pressure"]

            # Recalculate plastic waste based on updated temperature and pressure
            plastic_waste = calculate_plastic_waste(temperature, pressure)

            # Simulate executing the strategy (This should be executed on target layer)
            updated_production_data = {
                "temperature": temperature,
                "pressure": pressure,
                "plastic_waste": plastic_waste,
                "machine_status": "running",
            }
            
            print(f"4. Strategy Execution Layer: Updated production data -> {json.dumps(updated_production_data)}", end = "\n")
            data_queue.put(updated_production_data)
            time.sleep(1)
            strategy_enactment_done.set()

threads = [
    threading.Thread(target=goal_management),
    threading.Thread(target=data_collector),
    threading.Thread(target=strategy_management),
    threading.Thread(target=strategy_enactment),
]

for thread in threads:
    thread.start()